"""
Quantum Attention Validation Suite
===================================
Tests whether quantum attention truly solves circuit collapse at scale.

Key Tests:
1. Scale Robustness: Train with 10, 20, 30 pairs (vs original 5)
2. Complexity Test: Harder semantic relationships (abstract concepts, cross-domain)
3. Direct Comparison: Run variational circuit on same data to show difference

Expected Time: ~8 minutes on quantum hardware
"""

import numpy as np
import json
import sys
import os
from datetime import datetime
from typing import List, Tuple, Dict, Optional
import argparse

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from qiskit import QuantumCircuit
from qiskit.circuit import ParameterVector
from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2
from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager
from qiskit.circuit.library import RealAmplitudes, TwoLocal

from utils.data_preparation import QManifoldDataPreparation
from quantum_attention import QuantumTransformer


class ValidationSuite:
    """Comprehensive validation of quantum attention vs variational circuits."""

    def __init__(self, use_hardware: bool = False):
        self.use_hardware = use_hardware
        self.data_prep = QManifoldDataPreparation(target_dim=20)

        # Setup hardware if needed
        self.backend = None
        if use_hardware:
            service = QiskitRuntimeService(
                channel="ibm_cloud",
                token="HSP1Wlz3khkZBy8BvtynbTXJLS_6jWTiVYyeavQqXUsA",
                instance="crn:v1:bluemix:public:quantum-computing:us-east:a/5dc1b48400fa455fa966bf1ce087ccf1:ff0e794b-e42a-4ead-a9a4-2b9a8444e29f::"
            )
            self.backend = service.backend("ibm_fez")
            print(f"Using hardware: {self.backend.name}")

    def get_harder_test_pairs(self) -> List[Tuple[str, str]]:
        """Get challenging test pairs that typically cause circuit collapse."""
        return [
            # Abstract concepts (hardest for quantum circuits)
            ('democracy', 'freedom'),
            ('justice', 'fairness'),
            ('time', 'eternity'),
            ('reality', 'existence'),
            ('consciousness', 'awareness'),

            # Cross-domain relationships
            ('mathematics', 'piano'),  # Both have patterns/structure
            ('ocean', 'democracy'),     # Both have waves/currents
            ('atom', 'solar_system'),   # Similar structure
            ('dna', 'language'),        # Both encode information
            ('river', 'story'),         # Both flow and have narrative

            # Fine-grained distinctions
            ('happy', 'joyful'),
            ('sad', 'melancholy'),
            ('walk', 'stroll'),
            ('speak', 'orate'),
            ('think', 'ponder')
        ]

    def build_variational_circuit(self, n_qubits: int = 20) -> QuantumCircuit:
        """Build standard variational circuit (known to collapse)."""
        qc = QuantumCircuit(n_qubits)

        # Use RealAmplitudes - the architecture that failed before
        ansatz = RealAmplitudes(n_qubits, reps=2)
        qc.compose(ansatz, inplace=True)

        return qc

    def compute_variational_similarity(self, v1: np.ndarray, v2: np.ndarray,
                                      theta: np.ndarray, shots: int = 1024) -> float:
        """Compute similarity using variational circuit."""
        qc = QuantumCircuit(20)

        # Encode vectors
        for i in range(min(len(v1), 20)):
            qc.ry(float(v1[i]), i)

        # Variational layers (RealAmplitudes pattern)
        param_idx = 0
        for layer in range(2):
            # Rotation layer
            for i in range(20):
                if param_idx < len(theta):
                    qc.ry(theta[param_idx], i)
                    param_idx += 1

            # Entanglement layer
            for i in range(19):
                qc.cx(i, i + 1)

        # Encode second vector
        for i in range(min(len(v2), 20)):
            qc.ry(float(-v2[i]), i)

        qc.measure_all()

        if self.backend is not None:
            # Hardware execution
            pm = generate_preset_pass_manager(optimization_level=1, backend=self.backend)
            isa_circuit = pm.run(qc)
            sampler = SamplerV2(mode=self.backend)
            job = sampler.run([isa_circuit], shots=shots)
            result = job.result()
            counts = result[0].data.meas.get_counts()
        else:
            # Simulator
            from qiskit_aer import AerSimulator
            simulator = AerSimulator()
            job = simulator.run(qc, shots=shots)
            counts = job.result().get_counts()

        # Similarity = probability of |00...0>
        similarity = counts.get('0' * 20, 0) / shots
        return similarity

    def run_scale_test(self, n_pairs_list: List[int] = [5, 10, 20, 30]) -> Dict:
        """Test quantum attention at different scales."""
        print("\n" + "=" * 70)
        print("SCALE ROBUSTNESS TEST")
        print("=" * 70)
        print("Testing if quantum attention maintains performance with more training data")

        results = {}

        for n_pairs in n_pairs_list:
            print(f"\n--- Training with {n_pairs} pairs ---")

            # Get data
            all_pairs = self.data_prep.get_default_concept_pairs()
            train_pairs = all_pairs[:n_pairs]
            test_pairs = all_pairs[n_pairs:n_pairs + 10]

            # Prepare embeddings
            all_concepts = self.data_prep.generate_all_concepts(all_pairs[:n_pairs + 10])
            embeddings = self.data_prep.embed_concepts(all_concepts)
            vectors_pca = self.data_prep.pca.fit_transform(embeddings)
            vectors_scaled = self.data_prep.scaler.fit_transform(vectors_pca)

            # Initialize quantum transformer
            qtransformer = QuantumTransformer(n_qubits=20, n_heads=4, n_layers=1)

            # Quick training (1 epoch for speed)
            train_loss = 0.0
            train_predictions = []
            train_targets = []

            for c1, c2 in train_pairs:
                try:
                    idx1 = all_concepts.index(c1)
                    idx2 = all_concepts.index(c2)
                except ValueError:
                    continue

                v1 = vectors_scaled[idx1]
                v2 = vectors_scaled[idx2]
                v1_pca = vectors_pca[idx1]
                v2_pca = vectors_pca[idx2]

                # Target
                dist = self.data_prep.compute_hyperbolic_distance(v1_pca, v2_pca)
                target = self.data_prep.hyperbolic_similarity(dist)
                train_targets.append(target)

                # Prediction
                pred = qtransformer.compute_similarity(v1, v2, backend=self.backend, shots=256)
                train_predictions.append(pred)

                train_loss += (pred - target) ** 2

            # Test evaluation
            test_predictions = []
            test_targets = []

            for c1, c2 in test_pairs:
                try:
                    idx1 = all_concepts.index(c1)
                    idx2 = all_concepts.index(c2)
                except ValueError:
                    continue

                v1 = vectors_scaled[idx1]
                v2 = vectors_scaled[idx2]
                v1_pca = vectors_pca[idx1]
                v2_pca = vectors_pca[idx2]

                # Target
                dist = self.data_prep.compute_hyperbolic_distance(v1_pca, v2_pca)
                target = self.data_prep.hyperbolic_similarity(dist)
                test_targets.append(target)

                # Prediction
                pred = qtransformer.compute_similarity(v1, v2, backend=self.backend, shots=512)
                test_predictions.append(pred)

            # Calculate metrics
            train_corr = np.corrcoef(train_predictions, train_targets)[0, 1] if len(train_predictions) > 1 else 0
            test_corr = np.corrcoef(test_predictions, test_targets)[0, 1] if len(test_predictions) > 1 else 0

            results[n_pairs] = {
                'train_correlation': float(train_corr),
                'test_correlation': float(test_corr),
                'train_loss': float(train_loss / len(train_pairs)) if train_pairs else 0
            }

            print(f"  Train correlation: {train_corr:.4f}")
            print(f"  Test correlation: {test_corr:.4f}")

            # Stop if correlation drops below threshold (circuit collapse)
            if test_corr < 0.3:
                print(f"  ‚ö†Ô∏è WARNING: Correlation dropped below 0.3 - potential collapse!")

        return results

    def run_complexity_test(self) -> Dict:
        """Test on harder semantic relationships."""
        print("\n" + "=" * 70)
        print("COMPLEXITY TEST")
        print("=" * 70)
        print("Testing on abstract concepts and cross-domain relationships")

        # Train on simple pairs
        simple_pairs = [
            ('cat', 'dog'),
            ('car', 'truck'),
            ('apple', 'orange'),
            ('chair', 'table'),
            ('red', 'blue')
        ]

        # Test on hard pairs
        hard_pairs = self.get_harder_test_pairs()

        # Prepare all concepts
        all_concepts = self.data_prep.generate_all_concepts(simple_pairs + hard_pairs)
        embeddings = self.data_prep.embed_concepts(all_concepts)
        vectors_pca = self.data_prep.pca.fit_transform(embeddings)
        vectors_scaled = self.data_prep.scaler.fit_transform(vectors_pca)

        # Test both architectures
        results = {}

        for arch_name, use_attention in [('variational', False), ('attention', True)]:
            print(f"\n--- Testing {arch_name} architecture ---")

            if use_attention:
                model = QuantumTransformer(n_qubits=20, n_heads=4, n_layers=1)
                compute_sim = lambda v1, v2: model.compute_similarity(v1, v2, backend=self.backend, shots=512)
            else:
                theta = np.random.uniform(-0.1, 0.1, 60)  # Same param count
                compute_sim = lambda v1, v2: self.compute_variational_similarity(v1, v2, theta, shots=512)

            # Quick training on simple pairs
            for _ in range(2):  # 2 quick iterations
                for c1, c2 in simple_pairs:
                    idx1 = all_concepts.index(c1)
                    idx2 = all_concepts.index(c2)
                    v1 = vectors_scaled[idx1]
                    v2 = vectors_scaled[idx2]
                    _ = compute_sim(v1, v2)

            # Test on hard pairs
            predictions = []
            targets = []

            for c1, c2 in hard_pairs[:8]:  # Limit to 8 for time
                try:
                    idx1 = all_concepts.index(c1)
                    idx2 = all_concepts.index(c2)

                    v1 = vectors_scaled[idx1]
                    v2 = vectors_scaled[idx2]
                    v1_pca = vectors_pca[idx1]
                    v2_pca = vectors_pca[idx2]

                    # Target
                    dist = self.data_prep.compute_hyperbolic_distance(v1_pca, v2_pca)
                    target = self.data_prep.hyperbolic_similarity(dist)
                    targets.append(target)

                    # Prediction
                    pred = compute_sim(v1, v2)
                    predictions.append(pred)

                    print(f"  {c1} ‚Üî {c2}: target={target:.3f}, pred={pred:.3f}")
                except:
                    continue

            # Calculate correlation
            correlation = np.corrcoef(predictions, targets)[0, 1] if len(predictions) > 1 else 0

            results[arch_name] = {
                'correlation': float(correlation),
                'predictions': predictions,
                'targets': targets
            }

            print(f"  Correlation on hard pairs: {correlation:.4f}")

            if correlation < 0.1:
                print(f"  ‚ùå CIRCUIT COLLAPSE DETECTED!")
            elif correlation > 0.5:
                print(f"  ‚úÖ Architecture handles complexity well!")

        return results

    def run_direct_comparison(self, n_pairs: int = 10) -> Dict:
        """Direct comparison: quantum attention vs variational on same data."""
        print("\n" + "=" * 70)
        print("DIRECT COMPARISON TEST")
        print("=" * 70)
        print(f"Both architectures trained on same {n_pairs} pairs")

        # Get data
        all_pairs = self.data_prep.get_default_concept_pairs()
        train_pairs = all_pairs[:n_pairs]
        test_pairs = all_pairs[n_pairs:n_pairs + 10]

        # Prepare embeddings
        all_concepts = self.data_prep.generate_all_concepts(all_pairs[:n_pairs + 10])
        embeddings = self.data_prep.embed_concepts(all_concepts)
        vectors_pca = self.data_prep.pca.fit_transform(embeddings)
        vectors_scaled = self.data_prep.scaler.fit_transform(vectors_pca)

        results = {}

        for arch_name in ['variational', 'attention']:
            print(f"\n--- {arch_name.upper()} ARCHITECTURE ---")

            if arch_name == 'attention':
                model = QuantumTransformer(n_qubits=20, n_heads=4, n_layers=1)
                compute_sim = lambda v1, v2, theta=None: model.compute_similarity(v1, v2, theta, backend=self.backend, shots=512)
                theta = model.theta
            else:
                theta = np.random.uniform(-0.1, 0.1, 60)
                compute_sim = lambda v1, v2, theta: self.compute_variational_similarity(v1, v2, theta, shots=512)

            # Training (1 epoch)
            best_theta = theta.copy()
            best_loss = float('inf')

            for iteration in range(3):  # 3 quick iterations
                epoch_loss = 0.0
                train_predictions = []
                train_targets = []

                for c1, c2 in train_pairs:
                    idx1 = all_concepts.index(c1)
                    idx2 = all_concepts.index(c2)

                    v1 = vectors_scaled[idx1]
                    v2 = vectors_scaled[idx2]
                    v1_pca = vectors_pca[idx1]
                    v2_pca = vectors_pca[idx2]

                    # Target
                    dist = self.data_prep.compute_hyperbolic_distance(v1_pca, v2_pca)
                    target = self.data_prep.hyperbolic_similarity(dist)
                    train_targets.append(target)

                    # Prediction
                    pred = compute_sim(v1, v2, theta)
                    train_predictions.append(pred)

                    loss = (pred - target) ** 2
                    epoch_loss += loss

                avg_loss = epoch_loss / len(train_pairs)

                if avg_loss < best_loss:
                    best_loss = avg_loss
                    best_theta = theta.copy()

                # Simple gradient update
                delta = np.random.choice([-1, 1], size=len(theta))
                theta += 0.1 * delta * (0.5 - avg_loss)

                train_corr = np.corrcoef(train_predictions, train_targets)[0, 1] if len(train_predictions) > 1 else 0
                print(f"  Iteration {iteration + 1}: loss={avg_loss:.4f}, corr={train_corr:.4f}")

            # Test with best parameters
            theta = best_theta
            test_predictions = []
            test_targets = []

            print("\n  Test Results:")
            for c1, c2 in test_pairs:
                idx1 = all_concepts.index(c1)
                idx2 = all_concepts.index(c2)

                v1 = vectors_scaled[idx1]
                v2 = vectors_scaled[idx2]
                v1_pca = vectors_pca[idx1]
                v2_pca = vectors_pca[idx2]

                # Target
                dist = self.data_prep.compute_hyperbolic_distance(v1_pca, v2_pca)
                target = self.data_prep.hyperbolic_similarity(dist)
                test_targets.append(target)

                # Prediction
                pred = compute_sim(v1, v2, theta)
                test_predictions.append(pred)

                print(f"    {c1} ‚Üî {c2}: target={target:.3f}, pred={pred:.3f}")

            test_corr = np.corrcoef(test_predictions, test_targets)[0, 1] if len(test_predictions) > 1 else 0

            results[arch_name] = {
                'train_loss': float(best_loss),
                'test_correlation': float(test_corr),
                'test_predictions': test_predictions,
                'test_targets': test_targets
            }

            print(f"\n  FINAL TEST CORRELATION: {test_corr:.4f}")

            if test_corr < 0.1:
                print("  ‚ùå CIRCUIT COLLAPSED!")
            elif test_corr > 0.7:
                print("  ‚úÖ EXCELLENT PERFORMANCE!")

        return results

    def run_full_validation(self) -> Dict:
        """Run complete validation suite."""
        print("\n" + "=" * 70)
        print("QUANTUM ATTENTION VALIDATION SUITE")
        print("=" * 70)

        all_results = {
            'timestamp': datetime.now().isoformat(),
            'hardware': self.use_hardware,
            'backend': self.backend.name if self.backend else 'simulator'
        }

        # Test 1: Scale robustness (quick version for time)
        print("\nüî¨ Test 1: Scale Robustness")
        scale_results = self.run_scale_test([5, 10, 20])
        all_results['scale_test'] = scale_results

        # Test 2: Direct comparison (most important)
        print("\nüî¨ Test 2: Direct Comparison")
        comparison_results = self.run_direct_comparison(10)
        all_results['direct_comparison'] = comparison_results

        # Save results
        output_file = f"../results/validation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w') as f:
            json.dump(all_results, f, indent=2)

        print(f"\n\nResults saved to {output_file}")

        # Summary
        print("\n" + "=" * 70)
        print("VALIDATION SUMMARY")
        print("=" * 70)

        # Scale test summary
        print("\nüìä Scale Test Results:")
        for n_pairs, metrics in scale_results.items():
            print(f"  {n_pairs} pairs: test_corr={metrics['test_correlation']:.4f}")

        # Comparison summary
        print("\nüìä Direct Comparison:")
        print(f"  Variational: {comparison_results['variational']['test_correlation']:.4f}")
        print(f"  Attention:   {comparison_results['attention']['test_correlation']:.4f}")

        # Final verdict
        attention_score = comparison_results['attention']['test_correlation']
        variational_score = comparison_results['variational']['test_correlation']

        print("\n" + "=" * 70)
        print("FINAL VERDICT")
        print("=" * 70)

        if attention_score > 0.7 and variational_score < 0.2:
            print("‚úÖ QUANTUM ATTENTION SOLVES CIRCUIT COLLAPSE!")
            print(f"   Attention: {attention_score:.4f} (SUCCESS)")
            print(f"   Variational: {variational_score:.4f} (COLLAPSED)")
            print("\nüéâ This validates Paper 5's central claim!")
        elif attention_score > variational_score + 0.3:
            print("‚ö†Ô∏è  QUANTUM ATTENTION SHOWS SIGNIFICANT ADVANTAGE")
            print(f"   Improvement: {attention_score - variational_score:.4f}")
        else:
            print("‚ùå NO CLEAR ADVANTAGE DEMONSTRATED")

        return all_results


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Validate Quantum Attention')
    parser.add_argument('--hardware', action='store_true', help='Use IBM Quantum hardware')
    parser.add_argument('--quick', action='store_true', help='Quick validation (fewer tests)')

    args = parser.parse_args()

    if args.hardware:
        print("WARNING: This will use quantum hardware!")
        print("Estimated time: 7-8 minutes")
        response = input("Continue? (y/n): ")
        if response.lower() != 'y':
            print("Aborted.")
            sys.exit(0)

    validator = ValidationSuite(use_hardware=args.hardware)

    if args.quick:
        # Just run direct comparison (most important test)
        print("\nRunning quick validation (direct comparison only)...")
        results = validator.run_direct_comparison(8)
    else:
        # Full validation suite
        results = validator.run_full_validation()

    print("\n‚úÖ Validation complete!")